{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7c15551-fc23-4b3e-9b6a-226b68544447",
   "metadata": {},
   "source": [
    "First, we'll do some setup. Create a LangSmith API Key by navigating to the settings page in LangSmith, then set the following environment variables.\n",
    "```\n",
    "OPENAI_API_KEY=<YOUR OPENAI API KEY>\n",
    "LANGCHAIN_TRACING_V2=true\n",
    "LANGCHAIN_PROJECT=<YOUR PROJECT NAME>\n",
    "LANGCHAIN_API_KEY=<YOUR LANGSMITH API KEY>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f18c847a-a7c1-4db5-a5f1-4f845e1a78a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bffce88-e0ec-4beb-9cba-6db6b7c159dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_examples = [\n",
    "    (\"Shut up, idiot\", \"Toxic\"),\n",
    "    (\"You're a wonderful person\", \"Not toxic\"),\n",
    "    (\"This is the worst thing ever\", \"Toxic\"),\n",
    "    (\"I had a great day today\", \"Not toxic\"),\n",
    "    (\"Nobody likes you\", \"Toxic\"),\n",
    "    (\"This movie is a masterpiece\", \"Not toxic\"),\n",
    "    (\"Go away and never come back\", \"Toxic\"),\n",
    "    (\"Thank you for your help\", \"Not toxic\"),\n",
    "    (\"This is so dumb\", \"Toxic\"),\n",
    "    (\"I appreciate your efforts\", \"Not toxic\"),\n",
    "    (\"This is a waste of time\", \"Toxic\"),\n",
    "    (\"This movie blows\", \"Toxic\"),\n",
    "    (\"This is unacceptable. I want to speak to the manager.\", \"Toxic\")\n",
    "]\n",
    "\n",
    "toxic_dataset_name = \"Toxic Queries Dataset\"\n",
    "toxic_dataset = client.create_dataset(dataset_name=toxic_dataset_name)\n",
    "for query, label in toxic_examples:\n",
    "    client.create_example(inputs={\"text\": query}, outputs={\"label\": label}, dataset_id=toxic_dataset.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3422c034-f298-4c0c-8903-50590038a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multi-turn examples\n",
    "multi_turn_examples = [\n",
    "    ([\"Recommend some family-friendly movies for tonight\", \"Do any of these have an educational theme?\", \"Which one has the highest ratings?\"],\n",
    "     [\"Some family-friendly movies available are 'The Lion King', 'Finding Nemo', and 'The Incredibles'\", \"'The Lion King' and 'Finding Nemo' have educational themes about the circle of life and the importance of family\", \"'The Incredibles' has the highest ratings among them with a 94% on Rotten Tomatoes\"]),\n",
    "    ([\"What are the top sci-fi movies on your service?\", \"Any recent ones?\", \"Can you suggest one that involves time travel?\"],\n",
    "     [\"Top sci-fi movies include 'Blade Runner 2049', 'Interstellar', and 'The Martian'\", \"A recent hit is 'Tenet', released in 2020\", \"'Interstellar' involves complex time travel themes and is highly recommended\"]),\n",
    "    ([\"I'm looking for movies directed by Christopher Nolan\", \"Which one would you recommend for a movie night?\", \"What's the plot of 'Inception'?\"],\n",
    "     [\"Christopher Nolan movies available include 'Inception', 'Dunkirk', and 'Interstellar'\", \"'Inception' is a great pick for a movie night, offering a mix of action, drama, and mind-bending storytelling\", \"'Inception' is about a thief who steals corporate secrets through dream-sharing technology and is given the inverse task of planting an idea into the mind of a CEO\"]),\n",
    "    ([\"Show me some popular romantic comedies\", \"Any classics in the list?\", \"Tell me more about 'When Harry Met Sally'\"],\n",
    "     [\"Popular romantic comedies include 'Crazy Rich Asians', 'The Big Sick', and 'When Harry Met Sally'\", \"'When Harry Met Sally' is considered a classic in the romantic comedy genre\", \"'When Harry Met Sally' explores the question of whether men and women can just be friends, through the story of its titular characters over the years\"]),\n",
    "    ([\"Do you have documentaries on nature?\", \"Which one focuses on marine life?\", \"How long is 'Blue Planet II'?\"],\n",
    "     [\"Yes, we have 'Planet Earth II', 'Blue Planet II', and 'Our Planet'\", \"'Blue Planet II' focuses extensively on marine life, exploring the deep ocean, coral reefs, and the open sea\", \"'Blue Planet II' is approximately 7 hours long, spread across 7 episodes\"])\n",
    "]\n",
    "\n",
    "multi_turn_dataset_name = \"Multi-Turn Queries\"\n",
    "multi_turn_dataset = client.create_dataset(dataset_name=multi_turn_dataset_name)\n",
    "for queries, answers in multi_turn_examples:\n",
    "    client.create_example(inputs={\"queries\": queries}, outputs={\"answers\": answers}, dataset_id=multi_turn_dataset.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30303995-cc66-4cba-ab82-7a81d1d90806",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_input_examples = [\n",
    "    ({\n",
    "        \"user_preferences\": [\"Sci-Fi\", \"Action\"],\n",
    "        \"watch_history\": [\"The Matrix\", \"Inception\"],\n",
    "        \"search_query\": \"What to watch next?\"\n",
    "     }, \n",
    "     \"Based on your love for Sci-Fi and Action movies, and considering you've recently watched 'The Matrix' and 'Inception', you might enjoy 'Blade Runner 2049' for its deep narrative and stunning visuals.\"),\n",
    "    \n",
    "    ({\n",
    "        \"user_preferences\": [\"Drama\", \"Historical\"],\n",
    "        \"watch_history\": [\"The Crown\", \"Downton Abbey\"],\n",
    "        \"search_query\": \"Looking for a movie with a strong storyline\"\n",
    "     }, \n",
    "     \"Given your interest in Drama and Historical themes, and your watch history, 'The King's Speech' offers a compelling storyline with remarkable performances.\"),\n",
    "    \n",
    "    ({\n",
    "        \"user_preferences\": [\"Comedy\", \"Romance\"],\n",
    "        \"watch_history\": [\"Friends\", \"The Big Bang Theory\"],\n",
    "        \"search_query\": \"Need a light-hearted movie\"\n",
    "     }, \n",
    "     \"Considering your preference for Comedy and Romance, along with enjoying shows like 'Friends', you'd likely enjoy 'Crazy Rich Asians' for its humor and heartwarming romance.\"),\n",
    "    \n",
    "    ({\n",
    "        \"user_preferences\": [\"Thriller\", \"Mystery\"],\n",
    "        \"watch_history\": [\"Sherlock\", \"Mindhunter\"],\n",
    "        \"search_query\": \"Suggest a suspenseful movie\"\n",
    "     }, \n",
    "     \"With your taste leaning towards Thriller and Mystery, and considering you've watched 'Sherlock' and 'Mindhunter', 'Gone Girl' would be an excellent choice for its suspense and plot twists.\"),\n",
    "    \n",
    "    ({\n",
    "        \"user_preferences\": [\"Documentary\", \"Nature\"],\n",
    "        \"watch_history\": [\"Planet Earth\", \"Blue Planet II\"],\n",
    "        \"search_query\": \"Want to watch something about wildlife\"\n",
    "     }, \n",
    "     \"Your interest in Documentaries and Nature, along with watching 'Planet Earth' and 'Blue Planet II', suggests you would enjoy 'The Serengeti Rules', which beautifully captures wildlife and ecosystems.\"),\n",
    "    \n",
    "    ({\n",
    "        \"user_preferences\": [\"Fantasy\", \"Adventure\"],\n",
    "        \"watch_history\": [\"Harry Potter series\", \"The Hobbit\"],\n",
    "        \"search_query\": \"Fantasy movies for the weekend?\"\n",
    "     }, \n",
    "     \"Given your love for Fantasy and Adventure, having watched the 'Harry Potter series' and 'The Hobbit', 'The Witcher' series would be a fantastic choice for your weekend binge.\"),\n",
    "    \n",
    "    ({\n",
    "        \"user_preferences\": [\"Animation\", \"Family\"],\n",
    "        \"watch_history\": [\"Finding Nemo\", \"Toy Story\"],\n",
    "        \"search_query\": \"Animated movies that are fun for all ages?\"\n",
    "     }, \n",
    "     \"With a preference for Animation and Family-friendly content, and given your history with 'Finding Nemo' and 'Toy Story', 'Coco' is highly recommended for its fun story and universal appeal.\"),\n",
    "    \n",
    "    ({\n",
    "        \"user_preferences\": [\"Horror\", \"Supernatural\"],\n",
    "        \"watch_history\": [\"The Haunting of Hill House\", \"Stranger Things\"],\n",
    "        \"search_query\": \"Scary movies that aren’t too gory?\"\n",
    "     }, \n",
    "     \"As a fan of Horror and Supernatural genres, and having enjoyed 'The Haunting of Hill House' and 'Stranger Things', 'A Quiet Place' offers suspense without relying on gore.\"),\n",
    "    \n",
    "    ({\n",
    "        \"user_preferences\": [\"Musical\", \"Drama\"],\n",
    "        \"watch_history\": [\"La La Land\", \"The Greatest Showman\"],\n",
    "        \"search_query\": \"Musicals with a strong emotional core?\"\n",
    "     }, \n",
    "     \"Your enjoyment of Musicals and Drama, seen in 'La La Land' and 'The Greatest Showman', means you might find 'Les Misérables' to be a powerful experience with its deep emotional resonance.\"),\n",
    "    \n",
    "    ({\n",
    "        \"user_preferences\": [\"Crime\", \"Legal Drama\"],\n",
    "        \"watch_history\": [\"Breaking Bad\", \"Better Call Saul\"],\n",
    "        \"search_query\": \"Engaging legal dramas?\"\n",
    "     }, \n",
    "     \"Considering your interest in Crime and Legal Drama, with 'Breaking Bad' and 'Better Call Saul' in your watch history, 'The Trial of the Chicago 7' is recommended for its engaging narrative and historical significance.\")\n",
    "]\n",
    "\n",
    "structured_input_dataset_name = \"Structured Inputs\"\n",
    "structured_input_dataset = client.create_dataset(dataset_name=structured_input_dataset_name)\n",
    "for inputs, answer in structured_input_examples:\n",
    "    client.create_example(inputs=inputs, outputs={\"answer\": answer}, dataset_id=structured_input_dataset.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb69a1af-87c4-4544-9be9-76d42c537655",
   "metadata": {},
   "source": [
    "## Toxic Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5576f715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from langsmith import wrappers, traceable\n",
    "\n",
    "openai = wrappers.wrap_openai(OpenAI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3de889d9-4e13-4f29-acab-01e4e44692a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable\n",
    "def label_query(text):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Given the following user query, assess whether it contains toxic content. Please provide a simple 'Toxic' or 'Not toxic' response based on your assessment.\"},\n",
    "        {\"role\": \"user\", \"content\": text}\n",
    "    ]\n",
    "    result = openai.chat.completions.create(messages=messages, model=\"gpt-3.5-turbo\", temperature=0)\n",
    "    return result.choices[0].message.content\n",
    "\n",
    "@traceable\n",
    "def label_query_alternate_prompt(text):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Please review the user query below and determine if it contains any form of toxic behavior, such as insults, threats, or highly negative comments. Respond with 'Toxic' if it does, and 'Not toxic' if it doesn't.\"},\n",
    "        {\"role\": \"user\", \"content\": text}\n",
    "    ]\n",
    "    result = openai.chat.completions.create(messages=messages, model=\"gpt-3.5-turbo\", temperature=0)\n",
    "    return result.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76961af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.smith import RunEvalConfig\n",
    "from langsmith.evaluation import EvaluationResult, run_evaluator\n",
    "\n",
    "@run_evaluator\n",
    "def correct_label(run, example) -> EvaluationResult:\n",
    "    score = run.outputs.get(\"output\") == example.outputs.get(\"label\")\n",
    "    return EvaluationResult(key=\"correct_label\", score=int(score))\n",
    "\n",
    "def session_eval(runs, examples):\n",
    "    correct = 0\n",
    "    for i, run in enumerate(runs):\n",
    "        if run.outputs['output']== examples[i].outputs['label']:\n",
    "            correct += 1\n",
    "    if correct / len(runs) > .5:\n",
    "        return {\"pass\": True}\n",
    "    else:\n",
    "        return {\"pass\": False}\n",
    "\n",
    "eval_config = RunEvalConfig(\n",
    "    custom_evaluators=[correct_label],\n",
    "    session_evaluators=[session_eval]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de86a367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'toxic queries prompt 001' at:\n",
      "https://smith.langchain.com/o/a6bd43c4-4dd6-4eac-b0f5-50007628e89b/datasets/e2461e51-b1d2-4277-b582-1856226f397b/compare?selectedSessions=ae688790-6ab8-4496-96e5-952eb892b14c\n",
      "\n",
      "View all tests for Dataset Toxic Queries Dataset at:\n",
      "https://smith.langchain.com/o/a6bd43c4-4dd6-4eac-b0f5-50007628e89b/datasets/e2461e51-b1d2-4277-b582-1856226f397b\n",
      "[------------------------------------------------->] 13/13"
     ]
    }
   ],
   "source": [
    "results_1 = client.run_on_dataset(\n",
    "    dataset_name=toxic_dataset_name,\n",
    "    llm_or_chain_factory=label_query,\n",
    "    evaluation=eval_config,\n",
    "    project_name=\"toxic queries prompt 001\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "547ebbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'toxic queries prompt 002' at:\n",
      "https://smith.langchain.com/o/a6bd43c4-4dd6-4eac-b0f5-50007628e89b/datasets/e2461e51-b1d2-4277-b582-1856226f397b/compare?selectedSessions=076354ee-6a67-473d-8725-de941d288dcd\n",
      "\n",
      "View all tests for Dataset Toxic Queries Dataset at:\n",
      "https://smith.langchain.com/o/a6bd43c4-4dd6-4eac-b0f5-50007628e89b/datasets/e2461e51-b1d2-4277-b582-1856226f397b\n",
      "[------------------------------------------------->] 13/13"
     ]
    }
   ],
   "source": [
    "results_2 = client.run_on_dataset(\n",
    "    dataset_name=toxic_dataset_name,\n",
    "    llm_or_chain_factory=label_query_alternate_prompt,\n",
    "    evaluation=eval_config,\n",
    "    project_name=\"toxic queries prompt 002\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f29e897-ad02-4647-b096-45f3000465f5",
   "metadata": {},
   "source": [
    "### Using the LangSmith Hub for Prompt Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5371b583-b2e3-4300-a303-5c74a1ed22d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'toxic queries prompt @6708c74f' at:\n",
      "https://smith.langchain.com/o/a6bd43c4-4dd6-4eac-b0f5-50007628e89b/datasets/e2461e51-b1d2-4277-b582-1856226f397b/compare?selectedSessions=a39a2fce-3cc9-4e14-b642-e38fed0f0c82\n",
      "\n",
      "View all tests for Dataset Toxic Queries Dataset at:\n",
      "https://smith.langchain.com/o/a6bd43c4-4dd6-4eac-b0f5-50007628e89b/datasets/e2461e51-b1d2-4277-b582-1856226f397b\n",
      "[------------------------------------------------->] 13/13"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_openai.chat_models.base import _convert_message_to_dict\n",
    "\n",
    "HUB_COMMIT_HASH = \"6708c74f\"\n",
    "\n",
    "obj = hub.pull(f\"ankushtest/toxic-query-labeler:{HUB_COMMIT_HASH}\")\n",
    "hub_messages = [_convert_message_to_dict(message.format()) for message in obj.messages]\n",
    "\n",
    "@traceable\n",
    "def label_query_hub(text):\n",
    "    messages = hub_messages + [{\"role\": \"user\", \"content\": text}]\n",
    "    result = openai.chat.completions.create(messages=messages, model=\"gpt-3.5-turbo\", temperature=0)\n",
    "    return result.choices[0].message.content\n",
    "\n",
    "results = client.run_on_dataset(\n",
    "    dataset_name=toxic_dataset_name,\n",
    "    llm_or_chain_factory=label_query_hub,\n",
    "    evaluation=eval_config,\n",
    "    project_name=f\"toxic queries prompt @{HUB_COMMIT_HASH}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f158db3e-eb72-4d0d-bb91-bbe305449d56",
   "metadata": {},
   "source": [
    "## Multi-Turn Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e62fc6fc-7911-44ed-a2d9-bed05d71a459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"retrieve_movies\",\n",
    "            \"description\": \"Retrieve a list of relevant movies and their metadata from a movie database.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The query used to retrieve movies from the movie database, for example 'Christopher Nolan films'\"\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\n",
    "Note that if the question does not require additional search and can be answered using the chat history, simply respond with the answer.\n",
    "Don't make up content that's not supplied in chat history.\n",
    "\"\"\"\n",
    "\n",
    "@traceable\n",
    "def generate_movie_search(chat_history, query):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "    ] + chat_history + [{\"role\": \"user\", \"content\": query}]\n",
    "    result = openai.chat.completions.create(\n",
    "        messages=messages, \n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        tools=tools\n",
    "    )\n",
    "    return result.choices[0].message\n",
    "\n",
    "def _convert_docs(results):\n",
    "    return [\n",
    "        {\n",
    "            \"page_content\": r,\n",
    "            \"type\": \"Document\",\n",
    "        } for r in results\n",
    "    ]\n",
    "\n",
    "@traceable(run_type=\"retriever\")\n",
    "def retrieve_movies(query):\n",
    "    # Foo retriever. In production, this would search an actual database\n",
    "    if \"family-friendly\" in query.lower():\n",
    "        return _convert_docs([\"Lion King\", \"Finding Nemo\", \"The Incredibles\"])\n",
    "    elif \"sci-fi\" in query.lower():\n",
    "        return _convert_docs([\"Blade Runner 2049\", \"Interstellar\", \"The Martian\"])\n",
    "    elif \"nature\" in query.lower():\n",
    "        return _convert_docs(['Planet Earth II', 'Blue Planet II', 'Our Planet'])\n",
    "    elif \"christopher nolan\" in query.lower():\n",
    "        return _convert_docs(['Inception', 'Dunkirk', 'Interstellar'])\n",
    "    else:\n",
    "        return _convert_docs(['Crazy Rich Asians', 'The Big Sick', 'When Harry Met Sally'])\n",
    "\n",
    "@traceable\n",
    "def execute_function_call(message):\n",
    "    if message.tool_calls[0].function.name == \"retrieve_movies\":\n",
    "        query = json.loads(message.tool_calls[0].function.arguments)[\"query\"]\n",
    "        results = retrieve_movies(query)\n",
    "    else:\n",
    "        results = f\"Error: function {message.tool_calls[0].function.name} does not exist\"\n",
    "    return results\n",
    "\n",
    "@traceable\n",
    "def generate_answer(question, context):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"Answer the user's question based only on the content below:\\n\\n{context}\"},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "    result = openai.chat.completions.create(messages=messages, model=\"gpt-3.5-turbo\", temperature=0)\n",
    "    return result.choices[0].message.content\n",
    "\n",
    "@traceable\n",
    "def rag_pipeline(chat_history, question):\n",
    "    message = generate_movie_search(chat_history, question)\n",
    "    if message.tool_calls is None:\n",
    "        return message.content\n",
    "    else:\n",
    "        docs = execute_function_call(message)\n",
    "        context = \"\\n\".join([doc[\"page_content\"] for doc in docs])\n",
    "        return generate_answer(question, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6cc965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multi_turn(example):\n",
    "    turns = example[\"queries\"]\n",
    "    chat_history, outputs = [], []\n",
    "    for turn in turns:\n",
    "        output = rag_pipeline(chat_history, turn)\n",
    "        chat_history.append({\"role\": \"user\", \"content\": turn})\n",
    "        chat_history.append({\"role\": \"assistant\", \"content\": output})\n",
    "        outputs.append(output)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7faf3611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.smith import RunEvalConfig\n",
    "from langsmith.evaluation import EvaluationResult, run_evaluator\n",
    "\n",
    "@run_evaluator\n",
    "def brief_response(run, example) -> EvaluationResult:\n",
    "    convo = run.outputs.get(\"output\") \n",
    "    for turn in convo:\n",
    "        if len(turn) > 200:\n",
    "            return EvaluationResult(key=\"brevity\", score=0)\n",
    "    return EvaluationResult(key=\"brevity\", score=1)\n",
    "\n",
    "eval_config = RunEvalConfig(\n",
    "    custom_evaluators=[brief_response]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed7178d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_turn_dataset_name = \"Multi-Turn Queries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b74b731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'multi turn eval 003' at:\n",
      "https://smith.langchain.com/o/a6bd43c4-4dd6-4eac-b0f5-50007628e89b/datasets/0868d724-39c1-43bb-9595-3733eccc3999/compare?selectedSessions=8f57fa7d-ddf0-428c-8265-2fbcbca16955\n",
      "\n",
      "View all tests for Dataset Multi-Turn Queries at:\n",
      "https://smith.langchain.com/o/a6bd43c4-4dd6-4eac-b0f5-50007628e89b/datasets/0868d724-39c1-43bb-9595-3733eccc3999\n",
      "[------------------------------------------------->] 5/5"
     ]
    }
   ],
   "source": [
    "results = client.run_on_dataset(\n",
    "    dataset_name=multi_turn_dataset_name,\n",
    "    llm_or_chain_factory=run_multi_turn,\n",
    "    evaluation=eval_config,\n",
    "    project_name=\"multi turn eval 003\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e88a33-7aed-4912-99fc-202758ad02bf",
   "metadata": {},
   "source": [
    "## Structured Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24d7864d-ecd3-4b7d-aabd-deccf45d2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_template = \"\"\"Respond to the user's search query given what you know about them.\n",
    "\n",
    "You know they just watched: {watch_history}\n",
    "\n",
    "You know they have explicited stated preferences for: {user_preferences}\"\"\"\n",
    "\n",
    "@traceable\n",
    "def generate_recomendation(search_query, watch_history, user_preferences):\n",
    "    system_prompt = system_prompt_template.format(\n",
    "        watch_history=watch_history, \n",
    "        user_preferences=user_preferences\n",
    "    )\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "    ] + [{\"role\": \"user\", \"content\": search_query}]\n",
    "    result = openai.chat.completions.create(\n",
    "        messages=messages, \n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "    )\n",
    "    return result.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe559c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import smith\n",
    "eval_config = smith.RunEvalConfig(\n",
    "    evaluators=[\n",
    "        \"cot_qa\"\n",
    "    ],\n",
    "    input_key=\"search_query\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6f913e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_input_dataset_name = \"Structured Inputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "688fb930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'recomendations 001' at:\n",
      "https://smith.langchain.com/o/a6bd43c4-4dd6-4eac-b0f5-50007628e89b/datasets/532f0898-1521-4528-84ec-8fef98148ae7/compare?selectedSessions=70515355-b037-49fc-ab02-0d5d07a0d9f8\n",
      "\n",
      "View all tests for Dataset Structured Inputs at:\n",
      "https://smith.langchain.com/o/a6bd43c4-4dd6-4eac-b0f5-50007628e89b/datasets/532f0898-1521-4528-84ec-8fef98148ae7\n",
      "[------------------------------------------------->] 10/10"
     ]
    }
   ],
   "source": [
    "result = client.run_on_dataset(\n",
    "    dataset_name=structured_input_dataset_name,\n",
    "    llm_or_chain_factory=lambda input: generate_recomendation(\n",
    "        input[\"search_query\"], input[\"watch_history\"], input['user_preferences']\n",
    "    ),\n",
    "    evaluation=eval_config,\n",
    "    project_name=\"recomendations 001\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623bb70a",
   "metadata": {},
   "source": [
    "## Dataset Versioning & Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa1d4408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18275fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Toxic Queries Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7aa208cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(client.list_examples(dataset_name=dataset_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2554c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Example(dataset_id=UUID('4a2a5704-37af-4368-a740-4273e735f800'), inputs={'text': 'hi there'}, outputs={'label': 'Not toxic'}, metadata={'recent': True}, id=UUID('e0fe67ef-5c8c-4f78-9810-1b19d0585a0b'), created_at=datetime.datetime(2024, 3, 3, 21, 2, 56, 768365, tzinfo=datetime.timezone.utc), modified_at=datetime.datetime(2024, 3, 3, 21, 2, 56, 768365, tzinfo=datetime.timezone.utc), runs=[], source_run_id=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_example(\n",
    "    inputs={\"text\": \"hi there\"},\n",
    "    outputs={\"label\": \"Not toxic\"},\n",
    "    metadata={\"recent\": True}, \n",
    "    dataset_name=dataset_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeb2f1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(client.list_examples(dataset_name=dataset_name, as_of=datetime.datetime.now(tz=datetime.timezone.utc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88b9e929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(client.list_examples(dataset_name=dataset_name, as_of=datetime.datetime(2024, 3, 3, 9))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1275901",
   "metadata": {},
   "source": [
    "# Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0506d0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from langsmith import wrappers, traceable\n",
    "\n",
    "openai = wrappers.wrap_openai(OpenAI(\n",
    "    base_url=\"https://eks.smith.langchain.dev/proxy/openai/\", \n",
    "    #default_headers={\"Cache-Control\": \"no-store\"}\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "454ef8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Generate a three paragraph description of a movie about this topic: {topic}.\"\"\"\n",
    "\n",
    "@traceable\n",
    "def generate_movie(topic):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": system_prompt.format(topic=topic)},\n",
    "    ]\n",
    "    result = openai.chat.completions.create(\n",
    "        messages=messages, \n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        tools=tools\n",
    "    )\n",
    "    return result.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f68bbbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable\n",
    "def generate_title(description):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": f\"Generate a title for the following movie description:\\n\\n{description}\"},\n",
    "    ]\n",
    "    result = openai.chat.completions.create(\n",
    "        messages=messages, \n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        tools=tools\n",
    "    )\n",
    "    return result.choices[0].message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b2734044",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable\n",
    "def pipeline(topic):\n",
    "    description = generate_movie(topic)\n",
    "    title = generate_title(description)\n",
    "    return {\n",
    "        \"description\": description,\n",
    "        \"title\": title\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25038102",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_creation_examples = [\n",
    "    \"soccer\",\n",
    "    \"a pop star\",\n",
    "    \"action movie in venice\"\n",
    "]\n",
    "\n",
    "movie_creation_dataset_name = \"Movie Creation Dataset\"\n",
    "movie_dataset = client.create_dataset(dataset_name=movie_creation_dataset_name)\n",
    "for topic in movie_creation_examples:\n",
    "    client.create_example(inputs={\"topic\": topic}, dataset_id=movie_dataset.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f25215f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'movie 1' at:\n",
      "https://smith.langchain.com/o/02564c5f-72ba-4057-8130-2b43b785bbd8/datasets/032409a9-371c-4c3f-a931-b36be692682c/compare?selectedSessions=bf1249c4-52a7-4071-8258-cd5c225702a9\n",
      "\n",
      "View all tests for Dataset Movie Creation Dataset at:\n",
      "https://smith.langchain.com/o/02564c5f-72ba-4057-8130-2b43b785bbd8/datasets/032409a9-371c-4c3f-a931-b36be692682c\n",
      "[------------------------------------------------->] 3/3"
     ]
    }
   ],
   "source": [
    "result = client.run_on_dataset(\n",
    "    dataset_name=movie_creation_dataset_name,\n",
    "    llm_or_chain_factory=lambda input: pipeline(\n",
    "        input[\"topic\"],\n",
    "    ),\n",
    "    project_name=\"movie 1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ad7ae07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable\n",
    "def generate_title(description):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": f\"Generate a title in SPANISH for the following movie description:\\n\\n{description}\"},\n",
    "    ]\n",
    "    result = openai.chat.completions.create(\n",
    "        messages=messages, \n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        tools=tools\n",
    "    )\n",
    "    return result.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "09b5eeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable\n",
    "def pipeline(topic):\n",
    "    description = generate_movie(topic)\n",
    "    title = generate_title(description)\n",
    "    return {\n",
    "        \"description\": description,\n",
    "        \"title\": title\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "27846f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'movie 2' at:\n",
      "https://smith.langchain.com/o/02564c5f-72ba-4057-8130-2b43b785bbd8/datasets/032409a9-371c-4c3f-a931-b36be692682c/compare?selectedSessions=69ce3ace-8626-49dd-a7fd-01b01b4fb23b\n",
      "\n",
      "View all tests for Dataset Movie Creation Dataset at:\n",
      "https://smith.langchain.com/o/02564c5f-72ba-4057-8130-2b43b785bbd8/datasets/032409a9-371c-4c3f-a931-b36be692682c\n",
      "[------------------------------------------------->] 3/3"
     ]
    }
   ],
   "source": [
    "result = client.run_on_dataset(\n",
    "    dataset_name=movie_creation_dataset_name,\n",
    "    llm_or_chain_factory=lambda input: pipeline(\n",
    "        input[\"topic\"],\n",
    "    ),\n",
    "    project_name=\"movie 2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0659d59c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
